{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules to load saved models\n",
    "from joblib import dump, load\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#data preprocessing modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#regression metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from commons import mean_absolute_percentage_error #keep commons.py in notebooks folder\n",
    "\n",
    "#classification metrics\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_auc_score, f1_score\n",
    "\n",
    "#modules for plots if required\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils import model_to_dot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.1-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\vanda\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.8/390.3 MB 16.8 MB/s eta 0:00:24\n",
      "   ---------------------------------------- 2.3/390.3 MB 24.0 MB/s eta 0:00:17\n",
      "   ---------------------------------------- 3.6/390.3 MB 25.4 MB/s eta 0:00:16\n",
      "    --------------------------------------- 4.9/390.3 MB 24.2 MB/s eta 0:00:16\n",
      "    --------------------------------------- 6.8/390.3 MB 28.8 MB/s eta 0:00:14\n",
      "    --------------------------------------- 8.7/390.3 MB 30.8 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 10.5/390.3 MB 31.2 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 12.6/390.3 MB 36.4 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 14.5/390.3 MB 40.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 16.4/390.3 MB 40.9 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 18.3/390.3 MB 43.7 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 20.2/390.3 MB 40.9 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 22.1/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 24.0/390.3 MB 38.6 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 25.9/390.3 MB 38.5 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 27.8/390.3 MB 43.7 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 29.6/390.3 MB 38.5 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 31.6/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 33.6/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 35.5/390.3 MB 38.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 37.4/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 39.3/390.3 MB 38.6 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 41.2/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 43.0/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 44.9/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 46.7/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 48.5/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 50.4/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 52.1/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 54.1/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 56.1/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 58.0/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 59.9/390.3 MB 40.9 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 61.8/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 63.7/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 65.6/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 67.4/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 69.4/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 71.2/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 73.2/390.3 MB 38.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 75.1/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 77.0/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 78.9/390.3 MB 38.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 80.8/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 82.8/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 84.5/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 85.9/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 88.1/390.3 MB 38.5 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 90.1/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 91.5/390.3 MB 36.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 92.7/390.3 MB 34.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 94.9/390.3 MB 36.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 97.2/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   --------- ----------------------------- 100.0/390.3 MB 40.9 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 101.9/390.3 MB 43.5 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 103.7/390.3 MB 46.7 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 105.7/390.3 MB 46.9 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 107.6/390.3 MB 43.7 MB/s eta 0:00:07\n",
      "   ---------- ---------------------------- 109.6/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 111.5/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 113.4/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 115.3/390.3 MB 38.6 MB/s eta 0:00:08\n",
      "   ----------- --------------------------- 116.2/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 116.6/390.3 MB 32.7 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 117.2/390.3 MB 29.8 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 118.2/390.3 MB 28.5 MB/s eta 0:00:10\n",
      "   ----------- --------------------------- 118.8/390.3 MB 26.2 MB/s eta 0:00:11\n",
      "   ----------- --------------------------- 119.4/390.3 MB 23.4 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 120.4/390.3 MB 22.6 MB/s eta 0:00:12\n",
      "   ------------ -------------------------- 120.7/390.3 MB 21.8 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 122.2/390.3 MB 19.9 MB/s eta 0:00:14\n",
      "   ------------ -------------------------- 123.5/390.3 MB 19.3 MB/s eta 0:00:14\n",
      "   ------------ -------------------------- 124.8/390.3 MB 19.3 MB/s eta 0:00:14\n",
      "   ------------ -------------------------- 126.8/390.3 MB 21.8 MB/s eta 0:00:13\n",
      "   ------------ -------------------------- 129.3/390.3 MB 29.7 MB/s eta 0:00:09\n",
      "   ------------- ------------------------- 131.2/390.3 MB 36.3 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 133.2/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 135.2/390.3 MB 46.9 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 137.1/390.3 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 139.0/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 141.0/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 142.9/390.3 MB 40.9 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 144.8/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 146.8/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 148.6/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 150.5/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 152.5/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 154.4/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 156.3/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   --------------- ----------------------- 158.3/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 160.2/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 162.1/390.3 MB 38.6 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 164.1/390.3 MB 40.9 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 165.8/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 167.3/390.3 MB 36.4 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 169.1/390.3 MB 38.6 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 170.8/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 172.6/390.3 MB 36.3 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 174.3/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 176.0/390.3 MB 34.4 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 177.8/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 179.7/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 181.6/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 183.4/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 185.3/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 186.9/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 188.7/390.3 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 190.4/390.3 MB 38.6 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 192.3/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 194.0/390.3 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 195.7/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 197.3/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 199.0/390.3 MB 36.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 200.6/390.3 MB 36.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 202.5/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 204.2/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 206.0/390.3 MB 36.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 207.9/390.3 MB 38.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 209.8/390.3 MB 36.3 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 211.7/390.3 MB 36.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 213.7/390.3 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 215.8/390.3 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 217.7/390.3 MB 43.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 219.6/390.3 MB 40.9 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 221.6/390.3 MB 43.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 223.6/390.3 MB 43.7 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 225.6/390.3 MB 40.9 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 227.6/390.3 MB 43.5 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 229.6/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 231.5/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 233.4/390.3 MB 43.7 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 235.2/390.3 MB 38.5 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 236.8/390.3 MB 36.4 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 238.7/390.3 MB 36.4 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 241.8/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 244.0/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 246.0/390.3 MB 46.7 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 248.0/390.3 MB 50.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 249.8/390.3 MB 46.7 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 251.9/390.3 MB 43.5 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 253.9/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 255.9/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 257.6/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 259.5/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 261.6/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 263.4/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 265.4/390.3 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 266.9/390.3 MB 38.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 268.7/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 270.5/390.3 MB 38.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 272.3/390.3 MB 38.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 274.1/390.3 MB 36.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 275.7/390.3 MB 36.3 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 277.4/390.3 MB 38.5 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 278.4/390.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 280.4/390.3 MB 36.3 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 282.4/390.3 MB 34.4 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 284.4/390.3 MB 36.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 286.4/390.3 MB 36.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 288.0/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 289.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 292.0/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 294.0/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 295.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 297.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 299.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 301.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 303.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 305.9/390.3 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 307.8/390.3 MB 43.7 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 309.7/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 311.7/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 313.7/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 315.7/390.3 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 317.7/390.3 MB 43.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 319.7/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 321.6/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 323.6/390.3 MB 43.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 325.6/390.3 MB 43.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 327.6/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 329.5/390.3 MB 43.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 331.5/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 333.5/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 335.1/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 337.2/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 339.5/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 341.4/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.4/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 345.3/390.3 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 347.3/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 349.3/390.3 MB 40.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 351.3/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 353.3/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 355.3/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 357.2/390.3 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 359.2/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 361.0/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 362.5/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 364.2/390.3 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 365.9/390.3 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 367.8/390.3 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 369.8/390.3 MB 36.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 371.8/390.3 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.3/390.3 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 374.7/390.3 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 376.1/390.3 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 378.8/390.3 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.8/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  382.6/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  384.7/390.3 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.6/390.3 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.6/390.3 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.2/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.3/390.3 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 390.3/390.3 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 1.7/4.3 MB 53.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.8/4.3 MB 48.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 39.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 25.1 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/26.4 MB 38.3 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 38.9 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.7/26.4 MB 36.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 7.6/26.4 MB 40.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.4/26.4 MB 37.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/26.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 13.2/26.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 15.1/26.4 MB 38.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 17.0/26.4 MB 38.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.6/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 23.0/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.8/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 31.2 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.5/127.5 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 1.0/5.5 MB 64.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.2/5.5 MB 41.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.4/5.5 MB 43.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 39.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.1-cp312-cp312-win_amd64.whl (292 kB)\n",
      "   ---------------------------------------- 0.0/292.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 292.0/292.0 kB 18.8 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 keras-3.6.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "data=pd.read_csv('datasets/reg_thirty.csv',sep=',')\n",
    "\n",
    "# 'datasets/reg_interval1.csv'\n",
    "# 'datasets/reg_interval2.csv'\n",
    "# 'datasets/reg_interval3.csv'\n",
    "# 'datasets/reg_seven.csv'\n",
    "# 'datasets/reg_thirty.csv'\n",
    "# 'datasets/reg_ninety.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activeaddresses</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>difficulty30mom</th>\n",
       "      <th>difficulty30rsi</th>\n",
       "      <th>difficulty90mom</th>\n",
       "      <th>hashrate90var</th>\n",
       "      <th>median_transaction_fee30trxUSD</th>\n",
       "      <th>median_transaction_feeUSD</th>\n",
       "      <th>mining_profitability</th>\n",
       "      <th>mining_profitability90rsi</th>\n",
       "      <th>...</th>\n",
       "      <th>price30wmaUSD</th>\n",
       "      <th>price3emaUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "      <th>price7smaUSD</th>\n",
       "      <th>price90wmaUSD</th>\n",
       "      <th>sentinusd90emaUSD</th>\n",
       "      <th>sentinusd90smaUSD</th>\n",
       "      <th>size90trx</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75756</td>\n",
       "      <td>6695826.0</td>\n",
       "      <td>2327950.0</td>\n",
       "      <td>97.889</td>\n",
       "      <td>3716190.0</td>\n",
       "      <td>1.292548e+26</td>\n",
       "      <td>2.482</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>7220.0</td>\n",
       "      <td>54.763</td>\n",
       "      <td>...</td>\n",
       "      <td>66.298</td>\n",
       "      <td>90.961</td>\n",
       "      <td>91.616</td>\n",
       "      <td>84.929</td>\n",
       "      <td>43.032</td>\n",
       "      <td>68391477</td>\n",
       "      <td>54550954</td>\n",
       "      <td>0.334</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>124.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91875</td>\n",
       "      <td>6695826.0</td>\n",
       "      <td>2327950.0</td>\n",
       "      <td>97.889</td>\n",
       "      <td>3716190.0</td>\n",
       "      <td>1.382186e+26</td>\n",
       "      <td>2.534</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>7990.0</td>\n",
       "      <td>55.757</td>\n",
       "      <td>...</td>\n",
       "      <td>69.605</td>\n",
       "      <td>99.355</td>\n",
       "      <td>100.288</td>\n",
       "      <td>90.078</td>\n",
       "      <td>44.686</td>\n",
       "      <td>73007549</td>\n",
       "      <td>57359476</td>\n",
       "      <td>0.331</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>111.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107142</td>\n",
       "      <td>6695826.0</td>\n",
       "      <td>2327950.0</td>\n",
       "      <td>97.889</td>\n",
       "      <td>3716190.0</td>\n",
       "      <td>1.460025e+26</td>\n",
       "      <td>2.599</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>8852.0</td>\n",
       "      <td>56.831</td>\n",
       "      <td>...</td>\n",
       "      <td>73.541</td>\n",
       "      <td>109.679</td>\n",
       "      <td>111.703</td>\n",
       "      <td>95.902</td>\n",
       "      <td>46.586</td>\n",
       "      <td>77645623</td>\n",
       "      <td>60260338</td>\n",
       "      <td>0.329</td>\n",
       "      <td>4478.0</td>\n",
       "      <td>102.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activeaddresses  difficulty  difficulty30mom  difficulty30rsi  \\\n",
       "0            75756   6695826.0        2327950.0           97.889   \n",
       "1            91875   6695826.0        2327950.0           97.889   \n",
       "2           107142   6695826.0        2327950.0           97.889   \n",
       "\n",
       "   difficulty90mom  hashrate90var  median_transaction_fee30trxUSD  \\\n",
       "0        3716190.0   1.292548e+26                           2.482   \n",
       "1        3716190.0   1.382186e+26                           2.534   \n",
       "2        3716190.0   1.460025e+26                           2.599   \n",
       "\n",
       "   median_transaction_feeUSD  mining_profitability  mining_profitability90rsi  \\\n",
       "0                     0.0474                7220.0                     54.763   \n",
       "1                     0.0539                7990.0                     55.757   \n",
       "2                     0.0600                8852.0                     56.831   \n",
       "\n",
       "   ...  price30wmaUSD  price3emaUSD  price3wmaUSD  price7smaUSD  \\\n",
       "0  ...         66.298        90.961        91.616        84.929   \n",
       "1  ...         69.605        99.355       100.288        90.078   \n",
       "2  ...         73.541       109.679       111.703        95.902   \n",
       "\n",
       "   price90wmaUSD  sentinusd90emaUSD  sentinusd90smaUSD  size90trx  \\\n",
       "0         43.032           68391477           54550954      0.334   \n",
       "1         44.686           73007549           57359476      0.331   \n",
       "2         46.586           77645623           60260338      0.329   \n",
       "\n",
       "   transactionvalueUSD  priceUSD  \n",
       "0               2592.0   124.662  \n",
       "1               4400.0   111.049  \n",
       "2               4478.0   102.694  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the data\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train-test splits for ANN\n",
    "length=data.shape[1]-1\n",
    "X=data.iloc[:,:length]\n",
    "y=data.iloc[:,length:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=True, random_state=7)\n",
    "y_train=np.ravel(y_train)\n",
    "y_test=np.ravel(y_test)\n",
    "estimators=[]\n",
    "estimators.append(['minmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scaling=Pipeline(estimators)\n",
    "X_train=scaling.fit_transform(X_train)\n",
    "X_test=scaling.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = 'trained_models/ANN_reg_thirty.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#load saved model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ANN\u001b[38;5;241m=\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrained_models/ANN_reg_thirty.h5\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    190\u001b[0m         filepath,\n\u001b[0;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[1;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(filepath, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = 'trained_models/ANN_reg_thirty.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "#load saved model\n",
    "ANN=load_model('trained_models/ANN_reg_thirty.h5',compile=False)\n",
    "\n",
    "# 'trained_models/ANN_reg_interval1.h5'\n",
    "# 'trained_models/ANN_reg_interval2.h5'\n",
    "# 'trained_models/ANN_reg_interval3.h5'\n",
    "# 'trained_models/ANN_reg_seven.h5'\n",
    "# 'trained_models/ANN_reg_thirty.h5'\n",
    "# 'trained_models/ANN_reg_ninety.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_1',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_1',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 20),\n",
       "    'dtype': 'float32',\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
       "     'config': {'mean': 0.0,\n",
       "      'stddev': 0.05,\n",
       "      'seed': None,\n",
       "      'dtype': 'float32'}},\n",
       "    'bias_initializer': {'class_name': 'Zeros',\n",
       "     'config': {'dtype': 'float32'}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_2',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None,\n",
       "      'dtype': 'float32'}},\n",
       "    'bias_initializer': {'class_name': 'Zeros',\n",
       "     'config': {'dtype': 'float32'}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_3',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
       "     'config': {'mean': 0.0,\n",
       "      'stddev': 0.05,\n",
       "      'seed': None,\n",
       "      'dtype': 'float32'}},\n",
       "    'bias_initializer': {'class_name': 'Zeros',\n",
       "     'config': {'dtype': 'float32'}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(ANN, show_layer_names=False, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred=ANN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred.ravel() #remove [] from y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>583.850</td>\n",
       "      <td>522.711670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>615.988</td>\n",
       "      <td>534.236450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234.619</td>\n",
       "      <td>239.523254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5260.000</td>\n",
       "      <td>5060.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>252.788</td>\n",
       "      <td>233.457977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>379.647</td>\n",
       "      <td>375.422241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>644.487</td>\n",
       "      <td>616.264648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7260.000</td>\n",
       "      <td>7679.484375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>312.724</td>\n",
       "      <td>311.261230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3780.000</td>\n",
       "      <td>3556.501953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>257.854</td>\n",
       "      <td>267.249451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5919.000</td>\n",
       "      <td>5819.637695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1075.000</td>\n",
       "      <td>920.870361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>365.837</td>\n",
       "      <td>384.004120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>335.738</td>\n",
       "      <td>357.061127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>119.685</td>\n",
       "      <td>92.515915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6122.000</td>\n",
       "      <td>6033.211914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>805.197</td>\n",
       "      <td>933.154663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8657.000</td>\n",
       "      <td>9233.719727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>609.706</td>\n",
       "      <td>590.236328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>589.032</td>\n",
       "      <td>631.067444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>437.341</td>\n",
       "      <td>437.689636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>476.384</td>\n",
       "      <td>509.848877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10426.000</td>\n",
       "      <td>9697.373047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>911.027</td>\n",
       "      <td>925.319458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3993.000</td>\n",
       "      <td>3946.294678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1189.000</td>\n",
       "      <td>1195.566772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>197.577</td>\n",
       "      <td>213.666748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>631.621</td>\n",
       "      <td>623.714233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>379.119</td>\n",
       "      <td>392.562073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>241.370</td>\n",
       "      <td>228.745499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>4508.000</td>\n",
       "      <td>4626.488281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>4509.000</td>\n",
       "      <td>4541.798828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>377.846</td>\n",
       "      <td>369.230408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>590.957</td>\n",
       "      <td>569.989624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>3392.000</td>\n",
       "      <td>3513.580322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>315.626</td>\n",
       "      <td>305.440308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>7025.000</td>\n",
       "      <td>6792.926758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>414.027</td>\n",
       "      <td>409.600464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>5882.000</td>\n",
       "      <td>6288.397461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>8266.000</td>\n",
       "      <td>8026.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>7127.000</td>\n",
       "      <td>7238.095703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>4421.000</td>\n",
       "      <td>4340.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>224.044</td>\n",
       "      <td>224.015808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>202.560</td>\n",
       "      <td>254.865906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>383.472</td>\n",
       "      <td>396.153198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>9782.000</td>\n",
       "      <td>10097.503906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>421.190</td>\n",
       "      <td>448.931702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>8176.000</td>\n",
       "      <td>8216.370117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>667.464</td>\n",
       "      <td>649.616455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>628.962</td>\n",
       "      <td>648.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>8601.000</td>\n",
       "      <td>8314.386719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>121.108</td>\n",
       "      <td>112.498146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>6951.000</td>\n",
       "      <td>7390.577148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>9304.000</td>\n",
       "      <td>9012.479492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>8273.000</td>\n",
       "      <td>7788.728516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>607.971</td>\n",
       "      <td>599.027161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>6044.000</td>\n",
       "      <td>6078.817383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>431.819</td>\n",
       "      <td>450.209808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>629.756</td>\n",
       "      <td>630.003784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        y_test        y_pred\n",
       "0      583.850    522.711670\n",
       "1      615.988    534.236450\n",
       "2      234.619    239.523254\n",
       "3     5260.000   5060.484375\n",
       "4      252.788    233.457977\n",
       "5      379.647    375.422241\n",
       "6      644.487    616.264648\n",
       "7     7260.000   7679.484375\n",
       "8      312.724    311.261230\n",
       "9     3780.000   3556.501953\n",
       "10     257.854    267.249451\n",
       "11    5919.000   5819.637695\n",
       "12    1075.000    920.870361\n",
       "13     365.837    384.004120\n",
       "14     335.738    357.061127\n",
       "15     119.685     92.515915\n",
       "16    6122.000   6033.211914\n",
       "17     805.197    933.154663\n",
       "18    8657.000   9233.719727\n",
       "19     609.706    590.236328\n",
       "20     589.032    631.067444\n",
       "21     437.341    437.689636\n",
       "22     476.384    509.848877\n",
       "23   10426.000   9697.373047\n",
       "24     911.027    925.319458\n",
       "25    3993.000   3946.294678\n",
       "26    1189.000   1195.566772\n",
       "27     197.577    213.666748\n",
       "28     631.621    623.714233\n",
       "29     379.119    392.562073\n",
       "..         ...           ...\n",
       "419    241.370    228.745499\n",
       "420   4508.000   4626.488281\n",
       "421   4509.000   4541.798828\n",
       "422    377.846    369.230408\n",
       "423    590.957    569.989624\n",
       "424   3392.000   3513.580322\n",
       "425    315.626    305.440308\n",
       "426   7025.000   6792.926758\n",
       "427    414.027    409.600464\n",
       "428   5882.000   6288.397461\n",
       "429   8266.000   8026.970703\n",
       "430   7127.000   7238.095703\n",
       "431   4421.000   4340.515625\n",
       "432    224.044    224.015808\n",
       "433    202.560    254.865906\n",
       "434    383.472    396.153198\n",
       "435   9782.000  10097.503906\n",
       "436    421.190    448.931702\n",
       "437   8176.000   8216.370117\n",
       "438    667.464    649.616455\n",
       "439    628.962    648.039062\n",
       "440   8601.000   8314.386719\n",
       "441    121.108    112.498146\n",
       "442   6951.000   7390.577148\n",
       "443   9304.000   9012.479492\n",
       "444   8273.000   7788.728516\n",
       "445    607.971    599.027161\n",
       "446   6044.000   6078.817383\n",
       "447    431.819    450.209808\n",
       "448    629.756    630.003784\n",
       "\n",
       "[449 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show predictions in tabular format\n",
    "combine=zip(y_test,y_pred)\n",
    "pd.DataFrame(combine,columns=['y_test','y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "mae=mean_absolute_error(y_test,y_pred)\n",
    "mape=mean_absolute_percentage_error(y_test, y_pred)\n",
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "r2=abs(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>90.120525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>4.834167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>175.594730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R^2</td>\n",
       "      <td>0.997019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0           1\n",
       "0   MAE   90.120525\n",
       "1  MAPE    4.834167\n",
       "2  RMSE  175.594730\n",
       "3   R^2    0.997019"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show metrics in tabular format\n",
    "metrics=[mae,mape,rmse,r2]\n",
    "metrics_labels=['MAE','MAPE','RMSE','R^2']\n",
    "pd.DataFrame(zip( metrics_labels,metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file path\n",
    "data=pd.read_csv('datasets/cls_seven.csv',sep=',')\n",
    "\n",
    "# 'datasets/cls_interval1.csv'\n",
    "# 'datasets/cls_interval2.csv'\n",
    "# 'datasets/cls_interval3.csv'\n",
    "# 'datasets/cls_seven.csv'\n",
    "# 'datasets/cls_thirty.csv'\n",
    "# 'datasets/cls_ninety.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activeaddresses</th>\n",
       "      <th>confirmationtime</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>difficulty30ema</th>\n",
       "      <th>difficulty3trx</th>\n",
       "      <th>difficulty7mom</th>\n",
       "      <th>difficulty7trx</th>\n",
       "      <th>difficulty90var</th>\n",
       "      <th>fee_to_reward90trxUSD</th>\n",
       "      <th>fee_to_rewardUSD</th>\n",
       "      <th>...</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>price90rocUSD</th>\n",
       "      <th>top100cap</th>\n",
       "      <th>top100cap30mom</th>\n",
       "      <th>top100cap30roc</th>\n",
       "      <th>top100cap30rsi</th>\n",
       "      <th>top100cap90rsi</th>\n",
       "      <th>transactions</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75756</td>\n",
       "      <td>7.273</td>\n",
       "      <td>6695826.0</td>\n",
       "      <td>5385392.0</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.593</td>\n",
       "      <td>1.168546e+12</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.867</td>\n",
       "      <td>...</td>\n",
       "      <td>81.308</td>\n",
       "      <td>606.456</td>\n",
       "      <td>19.962</td>\n",
       "      <td>0.694</td>\n",
       "      <td>3.600</td>\n",
       "      <td>65.405</td>\n",
       "      <td>50.301</td>\n",
       "      <td>52572</td>\n",
       "      <td>2592.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91875</td>\n",
       "      <td>7.956</td>\n",
       "      <td>6695826.0</td>\n",
       "      <td>5469936.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.333</td>\n",
       "      <td>1.243755e+12</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1.338</td>\n",
       "      <td>...</td>\n",
       "      <td>94.548</td>\n",
       "      <td>716.218</td>\n",
       "      <td>20.024</td>\n",
       "      <td>0.677</td>\n",
       "      <td>3.498</td>\n",
       "      <td>66.711</td>\n",
       "      <td>50.893</td>\n",
       "      <td>63095</td>\n",
       "      <td>4400.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107142</td>\n",
       "      <td>8.229</td>\n",
       "      <td>6695826.0</td>\n",
       "      <td>5549026.0</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.064</td>\n",
       "      <td>1.315554e+12</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.596</td>\n",
       "      <td>...</td>\n",
       "      <td>106.790</td>\n",
       "      <td>808.284</td>\n",
       "      <td>19.987</td>\n",
       "      <td>0.592</td>\n",
       "      <td>3.051</td>\n",
       "      <td>65.191</td>\n",
       "      <td>50.530</td>\n",
       "      <td>63766</td>\n",
       "      <td>4478.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   activeaddresses  confirmationtime  difficulty  difficulty30ema  \\\n",
       "0            75756             7.273   6695826.0        5385392.0   \n",
       "1            91875             7.956   6695826.0        5469936.0   \n",
       "2           107142             8.229   6695826.0        5549026.0   \n",
       "\n",
       "   difficulty3trx  difficulty7mom  difficulty7trx  difficulty90var  \\\n",
       "0           0.845             0.0           2.593     1.168546e+12   \n",
       "1           0.520             0.0           2.333     1.243755e+12   \n",
       "2           0.314             0.0           2.064     1.315554e+12   \n",
       "\n",
       "   fee_to_reward90trxUSD  fee_to_rewardUSD  ...  price90momUSD  price90rocUSD  \\\n",
       "0                  0.742             0.867  ...         81.308        606.456   \n",
       "1                  0.733             1.338  ...         94.548        716.218   \n",
       "2                  0.725             1.596  ...        106.790        808.284   \n",
       "\n",
       "   top100cap  top100cap30mom  top100cap30roc  top100cap30rsi  top100cap90rsi  \\\n",
       "0     19.962           0.694           3.600          65.405          50.301   \n",
       "1     20.024           0.677           3.498          66.711          50.893   \n",
       "2     19.987           0.592           3.051          65.191          50.530   \n",
       "\n",
       "   transactions  transactionvalueUSD  category  \n",
       "0         52572               2592.0         1  \n",
       "1         63095               4400.0         1  \n",
       "2         63766               4478.0         1  \n",
       "\n",
       "[3 rows x 41 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize the data\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train-test splits for SVM\n",
    "length=data.shape[1]-1\n",
    "X=data.iloc[:,:length]\n",
    "y=data.iloc[:,length:]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, shuffle=False, random_state=7)\n",
    "y_train=np.ravel(y_train)\n",
    "y_test=np.ravel(y_test)\n",
    "estimators=[]\n",
    "estimators.append(['minmax',MinMaxScaler()])\n",
    "estimators.append(['robust',RobustScaler()])\n",
    "scaling=Pipeline(estimators)\n",
    "X_train=scaling.fit_transform(X_train)\n",
    "X_test=scaling.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved model\n",
    "ANN=load_model('trained_models/ANN_cls_seven.hdf5',compile=False)\n",
    "\n",
    "# 'trained_models/ANN_cls_interval1.hdf5'\n",
    "# 'trained_models/ANN_cls_interval2.hdf5'\n",
    "# 'trained_models/ANN_cls_interval3.hdf5'\n",
    "# 'trained_models/ANN_cls_seven.hdf5'\n",
    "# 'trained_models/ANN_cls_thirty.hdf5'\n",
    "# 'trained_models/ANN_cls_ninety.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential_14',\n",
       " 'layers': [{'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_41',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 40),\n",
       "    'dtype': 'float32',\n",
       "    'units': 200,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
       "     'config': {'mean': 0.0,\n",
       "      'stddev': 0.05,\n",
       "      'seed': None,\n",
       "      'dtype': 'float32'}},\n",
       "    'bias_initializer': {'class_name': 'Zeros',\n",
       "     'config': {'dtype': 'float32'}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_42',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 200,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None,\n",
       "      'dtype': 'float32'}},\n",
       "    'bias_initializer': {'class_name': 'Zeros',\n",
       "     'config': {'dtype': 'float32'}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'dense_43',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 2,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "     'config': {'scale': 1.0,\n",
       "      'mode': 'fan_avg',\n",
       "      'distribution': 'uniform',\n",
       "      'seed': None,\n",
       "      'dtype': 'float32'}},\n",
       "    'bias_initializer': {'class_name': 'Zeros',\n",
       "     'config': {'dtype': 'float32'}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(ANN, show_layer_names=False, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred=ANN.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>494 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred\n",
       "0         1       0\n",
       "1         1       1\n",
       "2         1       1\n",
       "3         1       1\n",
       "4         1       1\n",
       "5         0       1\n",
       "6         0       1\n",
       "7         0       1\n",
       "8         0       1\n",
       "9         0       1\n",
       "10        0       1\n",
       "11        0       1\n",
       "12        1       1\n",
       "13        1       1\n",
       "14        1       1\n",
       "15        1       1\n",
       "16        1       1\n",
       "17        0       1\n",
       "18        1       0\n",
       "19        0       0\n",
       "20        1       1\n",
       "21        1       1\n",
       "22        1       1\n",
       "23        1       1\n",
       "24        1       1\n",
       "25        1       1\n",
       "26        1       1\n",
       "27        1       1\n",
       "28        0       1\n",
       "29        0       1\n",
       "..      ...     ...\n",
       "464       1       1\n",
       "465       1       1\n",
       "466       0       1\n",
       "467       0       1\n",
       "468       0       1\n",
       "469       0       1\n",
       "470       0       1\n",
       "471       0       1\n",
       "472       0       1\n",
       "473       0       1\n",
       "474       0       1\n",
       "475       0       1\n",
       "476       1       1\n",
       "477       1       1\n",
       "478       1       1\n",
       "479       1       1\n",
       "480       1       1\n",
       "481       1       1\n",
       "482       1       1\n",
       "483       1       1\n",
       "484       1       1\n",
       "485       0       1\n",
       "486       0       1\n",
       "487       0       1\n",
       "488       0       1\n",
       "489       0       1\n",
       "490       1       1\n",
       "491       1       1\n",
       "492       1       1\n",
       "493       1       1\n",
       "\n",
       "[494 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show predictions in tabular format\n",
    "combine=zip(y_test,y_pred)\n",
    "pd.DataFrame(combine,columns=['y_test','y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate metrics\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "f1=f1_score(y_test,y_pred, average='binary') # try average='binary' or 'weighted' take higher\n",
    "auc=roc_auc_score(y_test,y_pred)\n",
    "recall=recall_score(y_test,y_pred)\n",
    "precision=precision_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.512146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.651230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUC</td>\n",
       "      <td>0.532777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.957447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.493421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1\n",
       "0   Accuracy  0.512146\n",
       "1   F1-score  0.651230\n",
       "2        AUC  0.532777\n",
       "3     Recall  0.957447\n",
       "4  Precision  0.493421"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show metrics in tabular format\n",
    "metrics=[accuracy, f1, auc, recall, precision]\n",
    "metrics_labels=['Accuracy','F1-score','AUC','Recall','Precision']\n",
    "pd.DataFrame(zip( metrics_labels,metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
